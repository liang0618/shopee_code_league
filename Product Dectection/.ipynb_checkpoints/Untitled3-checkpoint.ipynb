{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.xception import Xception, preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model, load_model, save_model\n",
    "from tensorflow.keras.losses import categorical_crossentropy\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting. Can change.\n",
    "CLASSES = ['00','01','02','03','04','05','06','07','08','09','10','11','12','13','14','15','16','17','18','19','20','21','22','23','24','25','26','27','28','29','30','31','32','33','34','35','36','37','38','39','40','41']\n",
    "\n",
    "nClass = 42\n",
    "nPerTrain = 100      #550\n",
    "nPerTest = 12192       #150\n",
    "\n",
    "batch_size_init = 32\n",
    "batch_size_finetuning = 16\n",
    "\n",
    "lr_init = 1e-4\n",
    "lr_finetuning = 1e-6\n",
    "\n",
    "epochs_init = 10\n",
    "epochs_finetuning = 30\n",
    "epochs_all = epochs_init + epochs_finetuning\n",
    "\n",
    "#input image width, height and shape\n",
    "IMG_HEIGHT = 200\n",
    "IMG_WIDTH = 200\n",
    "IMG_SHAPE = (IMG_WIDTH, IMG_HEIGHT, 3)\n",
    "\n",
    "\n",
    "#define path\n",
    "dataset_dir = 'data/dataset'\n",
    "trained_model_dir = 'trained_model'\n",
    "results_dir = 'results'\n",
    "\n",
    "dir_name = 'VGG'\n",
    "\n",
    "model_checkpoint_dir = f'{trained_model_dir}/{dir_name}'\n",
    "if not os.path.exists(model_checkpoint_dir):\n",
    "    os.makedirs(model_checkpoint_dir)\n",
    "    \n",
    "model_init = os.path.join(model_checkpoint_dir, 'model_pre_final.h5')\n",
    "    \n",
    "chart_stats_dir = f'{results_dir}/{dir_name}'\n",
    "if not os.path.exists(chart_stats_dir):\n",
    "    os.makedirs(chart_stats_dir)\n",
    "\n",
    "train_dir = f'{dataset_dir}/small_data/train/'\n",
    "test_dir = f'{dataset_dir}/test/'\n",
    "pred_dir = f'{dataset_dir}/prediction3'\n",
    "train_00_dir = f'{train_dir}00'\n",
    "train_01_dir = f'{train_dir}01'\n",
    "train_02_dir = f'{train_dir}02'\n",
    "train_03_dir = f'{train_dir}03'\n",
    "train_04_dir = f'{train_dir}04'\n",
    "train_05_dir = f'{train_dir}05'\n",
    "train_06_dir = f'{train_dir}06'\n",
    "train_07_dir = f'{train_dir}07'\n",
    "train_08_dir = f'{train_dir}08'\n",
    "train_09_dir = f'{train_dir}09'\n",
    "train_10_dir = f'{train_dir}10'\n",
    "train_11_dir = f'{train_dir}11'\n",
    "train_12_dir = f'{train_dir}12'\n",
    "train_13_dir = f'{train_dir}13'\n",
    "train_14_dir = f'{train_dir}14'\n",
    "train_15_dir = f'{train_dir}15'\n",
    "train_16_dir = f'{train_dir}16'\n",
    "train_17_dir = f'{train_dir}17'\n",
    "train_18_dir = f'{train_dir}18'\n",
    "train_19_dir = f'{train_dir}19'\n",
    "train_20_dir = f'{train_dir}20'\n",
    "train_21_dir = f'{train_dir}21'\n",
    "train_22_dir = f'{train_dir}22'\n",
    "train_23_dir = f'{train_dir}23'\n",
    "train_24_dir = f'{train_dir}24'\n",
    "train_25_dir = f'{train_dir}25'\n",
    "train_26_dir = f'{train_dir}26'\n",
    "train_27_dir = f'{train_dir}27'\n",
    "train_28_dir = f'{train_dir}28'\n",
    "train_29_dir = f'{train_dir}29'\n",
    "train_30_dir = f'{train_dir}30'\n",
    "train_31_dir = f'{train_dir}31'\n",
    "train_32_dir = f'{train_dir}32'\n",
    "train_33_dir = f'{train_dir}33'\n",
    "train_34_dir = f'{train_dir}34'\n",
    "train_35_dir = f'{train_dir}35'\n",
    "train_36_dir = f'{train_dir}36'\n",
    "train_37_dir = f'{train_dir}37'\n",
    "train_38_dir = f'{train_dir}38'\n",
    "train_39_dir = f'{train_dir}39'\n",
    "train_40_dir = f'{train_dir}40'\n",
    "train_41_dir = f'{train_dir}41'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200\n",
      "12192\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#number of images\n",
    "num_00_tr = len(os.listdir(train_00_dir))\n",
    "num_01_tr = len(os.listdir(train_01_dir))\n",
    "num_02_tr = len(os.listdir(train_02_dir))\n",
    "num_03_tr = len(os.listdir(train_03_dir))\n",
    "num_04_tr = len(os.listdir(train_04_dir))\n",
    "num_05_tr = len(os.listdir(train_05_dir))\n",
    "num_06_tr = len(os.listdir(train_06_dir))\n",
    "num_07_tr = len(os.listdir(train_07_dir))\n",
    "num_08_tr = len(os.listdir(train_08_dir))\n",
    "num_09_tr = len(os.listdir(train_09_dir))\n",
    "num_10_tr = len(os.listdir(train_10_dir))\n",
    "num_11_tr = len(os.listdir(train_11_dir))\n",
    "num_12_tr = len(os.listdir(train_12_dir))\n",
    "num_13_tr = len(os.listdir(train_13_dir))\n",
    "num_14_tr = len(os.listdir(train_14_dir))\n",
    "num_15_tr = len(os.listdir(train_15_dir))\n",
    "num_16_tr = len(os.listdir(train_16_dir))\n",
    "num_17_tr = len(os.listdir(train_17_dir))\n",
    "num_18_tr = len(os.listdir(train_18_dir))\n",
    "num_19_tr = len(os.listdir(train_19_dir))\n",
    "num_20_tr = len(os.listdir(train_20_dir))\n",
    "num_21_tr = len(os.listdir(train_21_dir))\n",
    "num_22_tr = len(os.listdir(train_22_dir))\n",
    "num_23_tr = len(os.listdir(train_23_dir))\n",
    "num_24_tr = len(os.listdir(train_24_dir))\n",
    "num_25_tr = len(os.listdir(train_25_dir))\n",
    "num_26_tr = len(os.listdir(train_26_dir))\n",
    "num_27_tr = len(os.listdir(train_27_dir))\n",
    "num_28_tr = len(os.listdir(train_28_dir))\n",
    "num_29_tr = len(os.listdir(train_29_dir))\n",
    "num_30_tr = len(os.listdir(train_30_dir))\n",
    "num_31_tr = len(os.listdir(train_31_dir))\n",
    "num_32_tr = len(os.listdir(train_32_dir))\n",
    "num_33_tr = len(os.listdir(train_33_dir))\n",
    "num_34_tr = len(os.listdir(train_34_dir))\n",
    "num_35_tr = len(os.listdir(train_35_dir))\n",
    "num_36_tr = len(os.listdir(train_36_dir))\n",
    "num_37_tr = len(os.listdir(train_37_dir))\n",
    "num_38_tr = len(os.listdir(train_38_dir))\n",
    "num_39_tr = len(os.listdir(train_39_dir))\n",
    "num_40_tr = len(os.listdir(train_40_dir))\n",
    "num_41_tr = len(os.listdir(train_41_dir))\n",
    "\n",
    "\n",
    "num_test = len(os.listdir(test_dir))\n",
    "\n",
    "total_train = num_00_tr + num_01_tr + num_02_tr + num_03_tr + num_04_tr + num_05_tr + num_06_tr + num_07_tr + num_08_tr + num_09_tr + num_10_tr + num_11_tr + num_12_tr + num_13_tr + num_14_tr + num_15_tr + num_16_tr + num_17_tr + num_18_tr + num_19_tr + num_20_tr + num_21_tr + num_22_tr + num_23_tr + num_24_tr + num_25_tr + num_26_tr + num_27_tr + num_28_tr + num_29_tr + num_30_tr + num_31_tr + num_32_tr + num_33_tr + num_34_tr + num_35_tr + num_36_tr + num_37_tr + num_38_tr + num_39_tr + num_40_tr + num_41_tr \n",
    "total_test = num_test\n",
    "\n",
    "print(total_train)\n",
    "print(total_test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(batch_size, is_augment=False):\n",
    "    if is_augment:\n",
    "        datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input,\n",
    "            brightness_range=(0.4,0.9),\n",
    "            horizontal_flip=True,\n",
    "\n",
    "        )\n",
    "    else:\n",
    "        datagen = ImageDataGenerator(\n",
    "            preprocessing_function=preprocess_input\n",
    "        )\n",
    "\n",
    "\n",
    "    datagen = ImageDataGenerator(validation_split=0.2, rescale=1./255)\n",
    "    \n",
    "    train_generator = datagen.flow_from_directory(\n",
    "        train_dir, \n",
    "        subset='training',\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        classes=CLASSES,\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "\n",
    "    val_generator = datagen.flow_from_directory(\n",
    "        train_dir,\n",
    "        subset='validation',\n",
    "        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "        batch_size=batch_size,\n",
    "        classes=CLASSES,\n",
    "        class_mode=\"categorical\"\n",
    "    )\n",
    "    \n",
    "    return train_generator, val_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3360 images belonging to 42 classes.\n",
      "Found 840 images belonging to 42 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator, validation_generator = get_generator(batch_size_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tensorflow.python.keras.engine.input_layer.InputLayer object at 0x0000014DC75874A8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC75875F8> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DBBAB7828> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000014DC75A0F60> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC78FE588> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC79108D0> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000014DC7918B70> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC7918BE0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC793D390> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC7948630> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000014DC795B8D0> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC795BF60> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC796BF60> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC7990390> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000014DC799E630> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC799EF60> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC79AFE10> False\n",
      "<tensorflow.python.keras.layers.convolutional.Conv2D object at 0x0000014DC7F52F60> False\n",
      "<tensorflow.python.keras.layers.pooling.MaxPooling2D object at 0x0000014DC7F78390> False\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Model' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-d73ddf43b38f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# For VGG19 loading to sequential model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvgg_conv\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;31m# Create the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, layers, name)\u001b[0m\n\u001b[0;32m     91\u001b[0m         \u001b[1;31m# Add to the model any layers passed to the constructor.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 93\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mlayer\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     94\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'Model' object is not iterable"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-9525a678980d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Show a summary of the model. Check the number of trainable parameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Users\\Public\\Anaconda3\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1318\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1319\u001b[0m             raise ValueError(\n\u001b[1;32m-> 1320\u001b[1;33m                 \u001b[1;34m'This model has not yet been built. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1321\u001b[0m                 \u001b[1;34m'Build the model first by calling build() '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1322\u001b[0m                 \u001b[1;34m'or calling fit() with some data. '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling build() or calling fit() with some data. Or specify input_shape or batch_input_shape in the first layer for automatic build. "
     ]
    }
   ],
   "source": [
    "\n",
    "# Create the model\n",
    "model = tf.keras.Sequential()\n",
    "\n",
    "# Add the vgg convolutional base model\n",
    "\n",
    "model.add(VGG16_MODEL)\n",
    "\n",
    "# Add new layers\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Show a summary of the model. Check the number of trainable parameters\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
